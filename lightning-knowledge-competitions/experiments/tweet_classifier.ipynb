{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-based Disaster Tweet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/Kaggle-Knowledge-Competitions\n"
     ]
    }
   ],
   "source": [
    "# This cell assumes a project structure of: project-root/src/experiments/this_notebook.ipynb\n",
    "# We append the parent directory to the system path, so now we can import modules from src\n",
    "# We also create a variable named path which points to the project root.\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "path =  str(Path().resolve().parent.parent)\n",
    "\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and generate predictions with the trained model. Logging is done with TensorBoard, you can view them by running `tensorboard --logdir logs` on the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | net           | BertClassifier   | 108 M \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.244   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c694ed285447d5902b411d6b17972b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7eaaef20c249208a44c2e1826d6f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8494ca874a974c06a81e45a42cec70b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5fe017418747a2bd9b9e1d0edeca24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b02de123899495aa69b02d987397876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20f69bd39ee496784817bf0a4d41f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33268ec3da044c4095fda2cb8d9b4bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/Kaggle-Knowledge-Competitions/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9415169d664682bfe70d1737ec6379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 191it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from models.tweet_classifier import TweetClassifierModule\n",
    "from datasets.kaggle_tweets import KaggleTweetsDataModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=path+\"/logs\", name=\"lightning-tweet-classifier\")\n",
    "\n",
    "model = TweetClassifierModule(learning_rate=1e-6)\n",
    "\n",
    "# might have to change batch size and num_workers depending on your hardware\n",
    "data = KaggleTweetsDataModule(data_dir=path+\"/data/kaggle_tweets\",\n",
    "                            batch_size=32,\n",
    "                            num_workers=4)\n",
    "\n",
    "trainer = pl.Trainer(default_root_dir=path,\n",
    "                    max_epochs=5,\n",
    "                    gpus=1,\n",
    "                    precision=16,\n",
    "                    logger=logger,\n",
    "                    checkpoint_callback=False,\n",
    "                    log_every_n_steps=50,\n",
    "                    )\n",
    "trainer.fit(model, data)\n",
    "\n",
    "data.setup()\n",
    "raw_test_predictions = trainer.predict(model, data.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our raw prediction is currently a list of tuples representing the predictions for each batch. We want to turn this into two tensors, each the length of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def unpack_predictions(predictions):\n",
    "    \"\"\"Takes the output of trainer.predict and unpacks it into a tuple of two tensors\n",
    "    over the data set:\n",
    "        (imgs, predictions)\n",
    "    \"\"\"\n",
    "    # predictions start as list of lists of preds, of length num_batches.\n",
    "    # each tensor is 1D with length batch_size.\n",
    "    # we want to convert this to two tensors which are the length of the val/test set.\n",
    "    unpacked_predictions = torch.Tensor().to(predictions[0][0].device)\n",
    "    for batch in predictions:\n",
    "        preds = batch\n",
    "        unpacked_predictions = torch.cat([unpacked_predictions, preds], dim=0)\n",
    "\n",
    "    return unpacked_predictions\n",
    "\n",
    "predictions = unpack_predictions(raw_test_predictions)\n",
    "predictions = predictions.int().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save our predictions in the format for Kaggle submission. You can submit by running the following line:\n",
    "```bash\n",
    "# submits preds.csv to the mnist classification competition\n",
    "kaggle competitions submit -c nlp-getting-started -f data/kaggle_tweets/preds.csv --message first_submission_with_api\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# use sample submission to get the id of the predictions\n",
    "df = pd.read_csv(path+\"/data/kaggle_tweets/sample_submission.csv\")\n",
    "df[\"target\"] = predictions\n",
    "df.to_csv(path+\"/data/kaggle_tweets/preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbf7f804df088307e97e62d933cb62b93da59f5af49da0e68cca6c12b68e1ce1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
